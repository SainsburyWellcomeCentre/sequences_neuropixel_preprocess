{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1a79bd",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fe388cc-bff8-4adb-86d1-72b919a9fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from probeinterface.plotting import plot_probe\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797d127",
   "metadata": {},
   "source": [
    "# set paths and choose probe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "207cce56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\ap5\\\\ap5R_2024-11-20_09-00-27_saline',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\ap5\\\\ap5R_2024-11-21_09-21-32_ap5_ctb647',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\ap5\\\\ap5R_2024-11-25_09-41-07',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\ap5\\\\ap5R_2024-11-26_09-29-29_ap5_488',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq006_2024-11-25_09-37-51',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq006_2024-11-26_09-26-05',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq006_2024-11-27_09-46-17',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq006_2024-11-28_09-48-35',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq007_2024-11-29_10-29-42',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq008_2024-11-11_14-46-19',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq008_2024-11-12_12-58-20',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq008_2024-11-13_09-11-02',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq008_2024-11-15_14-05-31',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5lr_2024-11-15_09-53-24',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5L_2024-11-18_13-59-54',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5L_2024-11-19_14-17-24',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5R_2024-11-16_12-22-37',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5R_2024-11-18_08-34-11',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5R_2024-11-19_09-28-42',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-15_09-42-15',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-16_12-18-54',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-18_13-10-16',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-19_09-52-30',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-20_09-04-54',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-21_09-25-50',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq006_2024-11-22_09-34-41',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-18_08-51-40',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-19_14-14-27',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-20_13-27-15']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path_ = r\"Z:\\projects\\sequence_squad\\revision_data\\lars_recordings\\ephys\\\\\"\n",
    "\n",
    "base_recording_paths = []\n",
    "for q in os.listdir(path_):\n",
    "    if not 'other_sessions' in q:\n",
    "        folder = os.path.join(path_,q)\n",
    "        for q in os.listdir(folder):\n",
    "            base_recording_paths+=[os.path.join(folder,q)]\n",
    "            \n",
    "base_recording_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4bd2b",
   "metadata": {},
   "source": [
    "# make folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29fc6a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap5R\n",
      "2024-11-20\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-21\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-25\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-26\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-25\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-26\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-27\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-28\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq007\n",
      "2024-11-29\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq008\n",
      "2024-11-11\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq008\n",
      "2024-11-12\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq008\n",
      "2024-11-13\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq008\n",
      "2024-11-15\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5lr\n",
      "2024-11-15\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5L\n",
      "2024-11-18\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5L\n",
      "2024-11-19\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-16\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-18\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "ap5R\n",
      "2024-11-19\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-15\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-16\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-18\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-19\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-20\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-21\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq006\n",
      "2024-11-22\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq007\n",
      "2024-11-18\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq007\n",
      "2024-11-19\n",
      "mouse file already exists\n",
      "recording folder already exists\n",
      "seq007\n",
      "2024-11-20\n",
      "mouse file already exists\n",
      "recording folder already exists\n"
     ]
    }
   ],
   "source": [
    "all_recording_paths = []\n",
    "for i in range(len(base_recording_paths)):\n",
    "\n",
    "    organised_path = r\"Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\\"\n",
    "\n",
    "    mouse_id = base_recording_paths[i].split('\\\\')[-1].split('_')[0]\n",
    "    print(mouse_id)\n",
    "    date_ = base_recording_paths[i].split('\\\\')[-1].split('_')[1]\n",
    "    print(date_)\n",
    "    #reverse the date\n",
    "    date_ = '-'.join(date_.split('-')[::-1])\n",
    "\n",
    "    if not os.path.isdir(organised_path+mouse_id+'_implant1'):\n",
    "        print('adding mouse file')\n",
    "        os.makedirs(organised_path+mouse_id+'_implant1')\n",
    "    else:\n",
    "        print('mouse file already exists')\n",
    "        \n",
    "    #work out what rnum will be\n",
    "    make_folder = False\n",
    "    if len(os.listdir(organised_path+mouse_id+'_implant1\\\\')) == 0:\n",
    "        r_num = '1'\n",
    "        make_folder = True\n",
    "    else:\n",
    "        r_num = str(int(os.listdir(organised_path+mouse_id+'_implant1\\\\')[-1].split('_')[0][-1]) + 1)\n",
    "        for item in os.listdir(organised_path+mouse_id+'_implant1\\\\'):\n",
    "            if not date_ in item:\n",
    "                make_folder = True\n",
    "            else:\n",
    "                make_folder = False\n",
    "                r_num = item.split('_')[0].split('ing')[-1]\n",
    "                break\n",
    "        \n",
    "    # make recording dir\n",
    "    if make_folder == True:\n",
    "        print('**making new recording folder')\n",
    "        recording_path = organised_path+mouse_id+'_implant1' + '\\\\recording' + r_num + '_' + date_ + '\\\\'\n",
    "        os.makedirs(recording_path)\n",
    "        # make folder structure \n",
    "        if not os.path.isdir(recording_path + 'ephys'):\n",
    "            os.makedirs(recording_path + 'ephys')\n",
    "        if not os.path.isdir(recording_path + 'video/tracking/'):\n",
    "            os.makedirs(recording_path + 'video/tracking/')\n",
    "        if not os.path.isdir(recording_path + 'behav_sync/'):\n",
    "            os.makedirs(recording_path + 'behav_sync/') \n",
    "            \n",
    "\n",
    "    else:\n",
    "        print('recording folder already exists')\n",
    "        recording_path = organised_path+mouse_id+'_implant1' + '\\\\recording' + r_num + '_' + date_ + '\\\\'\n",
    "    all_recording_paths+=[recording_path + 'ephys']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f1919",
   "metadata": {},
   "source": [
    "# chose which data to process - ie. data that hasnt yet been processed - and create save paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d38f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "process_base_paths  = []\n",
    "out_paths = []\n",
    "missing_probe = []\n",
    "for index,path in enumerate(all_recording_paths):\n",
    "    if not os.path.isfile(path+ r'\\probeA\\unit_info.txt'):\n",
    "        # if no kilosort folder then add base path to process list\n",
    "        process_base_paths += [base_recording_paths[index]]\n",
    "        out_paths += [path]\n",
    "        missing_probe += ['A']\n",
    "\n",
    "    if not 'ap5' in path:\n",
    "        if not os.path.isfile(path+ r'\\probeB\\unit_info.txt'):\n",
    "            # if no kilosort folder then add base path to process list\n",
    "            process_base_paths += [base_recording_paths[index]]\n",
    "            out_paths += [path]\n",
    "            missing_probe += ['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c20c681-f035-4c80-8745-fa56e462b389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\dual_strd_hpc\\\\seq007_2024-11-29_10-29-42',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\ap5L_2024-11-18_13-59-54',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-18_08-51-40',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-19_14-14-27',\n",
       " 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\lars_recordings\\\\ephys\\\\\\\\learning\\\\seq007_2024-11-20_13-27-15']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_base_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a03a3",
   "metadata": {},
   "source": [
    "# kilosort loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b06ef65-1681-43da-a1e4-cef3d4c79bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2out of5\n",
      "*********** PROCESSING: ***********\n",
      "Z:\\projects\\sequence_squad\\revision_data\\lars_recordings\\ephys\\\\learning\\seq007_2024-11-18_08-51-40\n",
      "A\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\\recording1_18-11-2024\\ephys\n",
      "['Record Node 103#NI-DAQmx-102.PXIe-6341', 'Record Node 103#Neuropix-PXI-100.ProbeA', 'Record Node 103#Neuropix-PXI-100.ProbeB']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 52\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Preprocess the recording¶\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Let’s do something similar to the IBL destriping chain (See :ref:ibl_destripe) to preprocess the data but:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# instead of interpolating bad channels, we remove then.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# instead of highpass_spatial_filter() we use common_reference()\u001b[39;00m\n\u001b[0;32m     51\u001b[0m rec1 \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mhighpass_filter(raw_rec, freq_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400.\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m bad_channel_ids, channel_labels \u001b[38;5;241m=\u001b[39m \u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_bad_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m rec2 \u001b[38;5;241m=\u001b[39m rec1\u001b[38;5;241m.\u001b[39mremove_channels(bad_channel_ids)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad_channel_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, bad_channel_ids)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\preprocessing\\detect_bad_channels.py:151\u001b[0m, in \u001b[0;36mdetect_bad_channels\u001b[1;34m(recording, method, std_mad_threshold, psd_hf_threshold, dead_channel_threshold, noisy_channel_threshold, outside_channel_threshold, outside_channels_location, n_neighbors, nyquist_threshold, direction, chunk_duration_s, num_random_chunks, welch_window_ms, highpass_filter_cutoff, neighborhood_r2_threshold, neighborhood_r2_radius_um, seed)\u001b[0m\n\u001b[0;32m    148\u001b[0m     random_chunk_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_scaled\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     random_chunk_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcatenated\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m random_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_random_data_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_hp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_chunk_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m channel_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(recording\u001b[38;5;241m.\u001b[39mget_num_channels(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m channel_labels[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\core\\recording_tools.py:575\u001b[0m, in \u001b[0;36mget_random_data_chunks\u001b[1;34m(recording, return_scaled, num_chunks_per_segment, chunk_size, concatenated, seed, margin_frames)\u001b[0m\n\u001b[0;32m    573\u001b[0m     high \u001b[38;5;241m=\u001b[39m num_frames \u001b[38;5;241m-\u001b[39m chunk_size \u001b[38;5;241m-\u001b[39m margin_frames\n\u001b[0;32m    574\u001b[0m     random_starts \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mintegers(low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh, size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m--> 575\u001b[0m     segment_trace_chunk \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m            \u001b[49m\u001b[43msegment_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_starts\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    585\u001b[0m     chunk_list\u001b[38;5;241m.\u001b[39mextend(segment_trace_chunk)\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concatenated:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\core\\recording_tools.py:576\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    573\u001b[0m     high \u001b[38;5;241m=\u001b[39m num_frames \u001b[38;5;241m-\u001b[39m chunk_size \u001b[38;5;241m-\u001b[39m margin_frames\n\u001b[0;32m    574\u001b[0m     random_starts \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mintegers(low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh, size\u001b[38;5;241m=\u001b[39msize)\n\u001b[0;32m    575\u001b[0m     segment_trace_chunk \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 576\u001b[0m         \u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m            \u001b[49m\u001b[43msegment_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m start_frame \u001b[38;5;129;01min\u001b[39;00m random_starts\n\u001b[0;32m    583\u001b[0m     ]\n\u001b[0;32m    585\u001b[0m     chunk_list\u001b[38;5;241m.\u001b[39mextend(segment_trace_chunk)\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concatenated:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\core\\baserecording.py:346\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[1;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[0;32m    344\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_num_samples()\n\u001b[0;32m    345\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(end_frame, num_samples)) \u001b[38;5;28;01mif\u001b[39;00m end_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[1;32m--> 346\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\preprocessing\\filter.py:180\u001b[0m, in \u001b[0;36mFilterRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-backward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msos\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 180\u001b[0m         filtered_traces \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msosfiltfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraces_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         b, a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4479\u001b[0m, in \u001b[0;36msosfiltfilt\u001b[1;34m(sos, x, axis, padtype, padlen)\u001b[0m\n\u001b[0;32m   4477\u001b[0m ntaps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m n_sections \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4478\u001b[0m ntaps \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((sos[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(), (sos[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m-> 4479\u001b[0m edge, ext \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4480\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mntaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntaps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4482\u001b[0m \u001b[38;5;66;03m# These steps follow the same form as filtfilt with modifications\u001b[39;00m\n\u001b[0;32m   4483\u001b[0m zi \u001b[38;5;241m=\u001b[39m sosfilt_zi(sos)  \u001b[38;5;66;03m# shape (n_sections, 2) --> (n_sections, ..., 2, ...)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4257\u001b[0m, in \u001b[0;36m_validate_pad\u001b[1;34m(padtype, padlen, x, axis, ntaps)\u001b[0m\n\u001b[0;32m   4255\u001b[0m     ext \u001b[38;5;241m=\u001b[39m even_ext(x, edge, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   4256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124modd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 4257\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43modd_ext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4259\u001b[0m     ext \u001b[38;5;241m=\u001b[39m const_ext(x, edge, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\si_env\\Lib\\site-packages\\scipy\\signal\\_arraytools.py:103\u001b[0m, in \u001b[0;36modd_ext\u001b[1;34m(x, n, axis)\u001b[0m\n\u001b[0;32m    101\u001b[0m right_end \u001b[38;5;241m=\u001b[39m axis_slice(x, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    102\u001b[0m right_ext \u001b[38;5;241m=\u001b[39m axis_slice(x, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m(n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m--> 103\u001b[0m ext \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_ext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mright_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mright_ext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                     \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ext\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for ind,base_folder in enumerate(process_base_paths[2::]):\n",
    "    ind = ind + 2\n",
    "    \n",
    "    # clear gpu memory cache each loop to avoid memory issues\n",
    "    torch.cuda.empty_cache()\n",
    "    print(str(ind) + 'out of' + str(len(process_base_paths)))\n",
    "    print('*********** PROCESSING: ***********')\n",
    "    print(base_folder)\n",
    "    out_path = out_paths[ind]\n",
    "    \n",
    "    print(missing_probe[ind])\n",
    "    print(out_path)\n",
    "\n",
    "\n",
    "    # extract the stream names (each np processor)\n",
    "    stream_names, stream_ids = si.get_neo_streams('openephysbinary', base_folder)\n",
    "    print(stream_names)\n",
    "\n",
    "    # chose probe id, DEAL WITH PROBE A/B stuff\n",
    "    ksort = False\n",
    "    for stream_i, stream in enumerate(stream_names):\n",
    "        if 'Probe' + missing_probe[ind] in stream:\n",
    "            if not 'LFP' in stream:\n",
    "                Probe_id = stream_names[stream_i]\n",
    "                out_path = out_path + '\\\\probe' + missing_probe[ind] + '\\\\'\n",
    "                out_path_object = Path(out_path)\n",
    "                ksort = True\n",
    "                if not os.path.isdir(out_path):\n",
    "                    os.makedirs(out_path)\n",
    "                break\n",
    "\n",
    "    if ksort == True:\n",
    "        \n",
    "        # load in data\n",
    "        raw_rec = si.read_openephys(base_folder,stream_name = Probe_id,load_sync_channel=False)\n",
    "        raw_rec.get_probe().to_dataframe()\n",
    "    \n",
    "        # plot probe\n",
    "        fig, axs = plt.subplots(figsize=(1, 100))\n",
    "        probe = raw_rec.get_probe()\n",
    "        plot_probe(probe, ax = axs)\n",
    "        plt.savefig(out_path + 'probe_map.png')\n",
    "        plt.close()\n",
    "            \n",
    "        \n",
    "        # Preprocess the recording¶\n",
    "        # Let’s do something similar to the IBL destriping chain (See :ref:ibl_destripe) to preprocess the data but:\n",
    "        # instead of interpolating bad channels, we remove then.\n",
    "        # instead of highpass_spatial_filter() we use common_reference()\n",
    "        \n",
    "        rec1 = si.highpass_filter(raw_rec, freq_min=400.)\n",
    "        bad_channel_ids, channel_labels = si.detect_bad_channels(rec1)\n",
    "        rec2 = rec1.remove_channels(bad_channel_ids)\n",
    "        print('bad_channel_ids', bad_channel_ids)\n",
    "    \n",
    "        rec3 = si.phase_shift(rec2)\n",
    "        rec4 = si.common_reference(rec3, operator=\"median\", reference=\"global\")\n",
    "        rec = rec4\n",
    "        \n",
    "        ## save out the preprocessed binary\n",
    "        job_kwargs = dict(n_jobs=40, chunk_duration='1s', progress_bar=True)\n",
    "        rec = rec.save(folder=out_path_object / 'preprocess', format='binary', **job_kwargs, overwrite = True)\n",
    "        \n",
    "        # here we use static plot using matplotlib backend\n",
    "        fig, axs = plt.subplots(ncols=3, figsize=(20, 10))\n",
    "    \n",
    "        si.plot_traces(rec1, backend='matplotlib',  clim=(-50, 50), ax=axs[0])\n",
    "        si.plot_traces(rec4, backend='matplotlib',  clim=(-50, 50), ax=axs[1])\n",
    "        si.plot_traces(rec, backend='matplotlib',  clim=(-50, 50), ax=axs[2])\n",
    "        for i, label in enumerate(('filter', 'cmr', 'final')):\n",
    "            axs[i].set_title(label)\n",
    "        plt.savefig(out_path + 'preprocessing_destriping_common_ref.png')\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        # plot some channels\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        some_chans = rec.channel_ids[[100, 150, 200, ]]\n",
    "        si.plot_traces({'filter':rec1, 'cmr': rec4}, backend='matplotlib', mode='line', ax=ax, channel_ids=some_chans)\n",
    "        plt.savefig(out_path + 'example_chans.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # check noise \n",
    "        # we can estimate the noise on the scaled traces (microV) or on the raw one (which is in our case int16).\n",
    "        noise_levels_microV = si.get_noise_levels(rec, return_scaled=True)\n",
    "        noise_levels_int16 = si.get_noise_levels(rec, return_scaled=False)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        _ = ax.hist(noise_levels_microV, bins=np.arange(5, 30, 2.5))\n",
    "        ax.set_xlabel('noise  [microV]')\n",
    "        plt.savefig(out_path + 'noise_level.png')\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        # check default params for kilosort4\n",
    "        params_kilosort4 = si.get_default_sorter_params('kilosort4')\n",
    "        params_kilosort4['delete_recording_dat'] = False\n",
    "    \n",
    "        # # run kilosort4 with drift correction (set as True in the params)\n",
    "        sorting = si.run_sorter('kilosort4', rec, output_folder=out_path_object / 'kilosort4_output',\n",
    "                                docker_image=False, verbose=True, **params_kilosort4, remove_existing_folder = True)\n",
    "        \n",
    "        \n",
    "        ######################################################################################\n",
    "        # load back in to check quality\n",
    "        sorting = si.read_sorter_folder(out_path_object / 'kilosort4_output')\n",
    "        \n",
    "        analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, format=\"memory\")\n",
    "        \n",
    "        analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "        analyzer.compute(\"waveforms\",  ms_before=1.5,ms_after=2., **job_kwargs)\n",
    "        analyzer.compute(\"templates\", operators=[\"average\", \"median\", \"std\"])\n",
    "        analyzer.compute(\"noise_levels\")\n",
    "    \n",
    "        analyzer_saved = analyzer.save_as(folder=out_path_object / \"analyzer\", format=\"binary_folder\")\n",
    "    \n",
    "        metric_names=['firing_rate', 'presence_ratio', 'snr', 'isi_violation', 'amplitude_cutoff']\n",
    "    \n",
    "        metrics = si.compute_quality_metrics(analyzer, metric_names=metric_names)\n",
    "    \n",
    "        amplitude_cutoff_thresh = 0.1\n",
    "        isi_violations_ratio_thresh = 1\n",
    "        presence_ratio_thresh = 0.9\n",
    "    \n",
    "        our_query = f\"(amplitude_cutoff < {amplitude_cutoff_thresh}) & (isi_violations_ratio < {isi_violations_ratio_thresh}) & (presence_ratio > {presence_ratio_thresh})\"\n",
    "    \n",
    "        keep_units = metrics.query(our_query)\n",
    "        keep_unit_ids = keep_units.index.values\n",
    "    \n",
    "        analyzer_clean = analyzer.select_units(keep_unit_ids, folder=out_path_object / 'analyzer_clean', format='binary_folder')\n",
    "    \n",
    "        # export spike sorting report to a folder\n",
    "        si.export_report(analyzer_clean, out_path_object / 'report', format='png')\n",
    "\n",
    "        ### SAVE OUT A TXT FILE WITH NUMBER OF UNITS DATA ON IT\n",
    "        # Open a file in write mode\n",
    "        file_path = out_path + 'unit_info.txt'\n",
    "        with open(file_path, \"w\") as file:\n",
    "            # Use the file argument to save print output to the file\n",
    "            print('Kilosort output:',file = file)\n",
    "            print(sorting, file=file)\n",
    "            file.write(\"\\n\")\n",
    "            print('\"good\" units:',file = file)\n",
    "            print(analyzer_clean, file=file)\n",
    "\n",
    "        print('DONE!')\n",
    "    else:\n",
    "        print('Already processed or no probe B!')\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a7d329-c667-4bf7-9f73-757caae57ff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (3566307101.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "# # find peaks\n",
    "\n",
    "# from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "# from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "# break\n",
    "# job_kwargs = dict(n_jobs=40, chunk_duration='1s', progress_bar=True)\n",
    "# peaks = detect_peaks(rec,  method='locally_exclusive', noise_levels=noise_levels_int16,\n",
    "#                      detect_threshold=5, radius_um=50., **job_kwargs)\n",
    "\n",
    "# peak_locations = localize_peaks(rec, peaks, method='center_of_mass', radius_um=50., **job_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c187d-30f3-42ea-ae47-d66d3907382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for drifts\n",
    "# fs = rec.sampling_frequency\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# ax.scatter(peaks['sample_ind'] / fs, peak_locations['y'], color='k', marker='.',  alpha=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0080f5-0a41-426a-a31d-973fdd125d90",
   "metadata": {},
   "source": [
    "# Load back in to check quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d135ac-6c14-4a35-b3df-63e402c1ec5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7323d4b-2ee3-4dbd-b78f-28835daae20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmett\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\core\\job_tools.py:103: UserWarning: `n_jobs` is not set so parallel processing is disabled! To speed up computations, it is recommended to set n_jobs either globally (with the `spikeinterface.set_global_job_kwargs()` function) or locally (with the `n_jobs` argument). Use `spikeinterface.set_global_job_kwargs?` for more information about job_kwargs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e2de4f51ae406eb45316a779cfa5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_sparsity:   0%|          | 0/14682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SortingAnalyzer: 384 channels - 373 units - 1 segments - memory - sparse - has recording\n",
       "Loaded 0 extensions"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020c16d-3b25-440a-8f9a-cdadc7d48a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407f747849b3410b950c8a36841b82dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "compute_waveforms:   0%|          | 0/14682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SortingAnalyzer: 384 channels - 356 units - 1 segments - memory - sparse - has recording\n",
       "Loaded 4 extensions: random_spikes, waveforms, templates, noise_levels"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d89dd9-79c0-47a3-a376-d69abe7fba61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79e68bfb-00e5-4eda-b10a-3c105424b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a63ed-5345-482b-bb8e-40c50c4fb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmett\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\qualitymetrics\\misc_metrics.py:908: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firing_rate</th>\n",
       "      <th>presence_ratio</th>\n",
       "      <th>snr</th>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <th>isi_violations_count</th>\n",
       "      <th>amplitude_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.06766</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>2.156246</td>\n",
       "      <td>5.724791</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.00309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.276477</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>1.117945</td>\n",
       "      <td>10.729112</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.024969</td>\n",
       "      <td>0.408548</td>\n",
       "      <td>11</td>\n",
       "      <td>0.005223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.764291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.848011</td>\n",
       "      <td>3.078016</td>\n",
       "      <td>422</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.985189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.531435</td>\n",
       "      <td>0.030573</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.075003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.915325</td>\n",
       "      <td>0.176816</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.342204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.708582</td>\n",
       "      <td>0.919993</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2.283096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.799555</td>\n",
       "      <td>0.688189</td>\n",
       "      <td>158</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>7.896229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.028388</td>\n",
       "      <td>0.102685</td>\n",
       "      <td>282</td>\n",
       "      <td>0.083223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.616272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.235936</td>\n",
       "      <td>3.825898</td>\n",
       "      <td>64</td>\n",
       "      <td>0.032057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     firing_rate  presence_ratio       snr  isi_violations_ratio  \\\n",
       "0        2.06766        0.983607  2.156246              5.724791   \n",
       "1       1.276477        0.897541  1.117945             10.729112   \n",
       "2       0.781851             1.0  4.024969              0.408548   \n",
       "3       1.764291             1.0  1.848011              3.078016   \n",
       "4       2.985189             1.0  3.531435              0.030573   \n",
       "..           ...             ...       ...                   ...   \n",
       "351     1.075003             1.0  4.915325              0.176816   \n",
       "352     1.342204             1.0  2.708582              0.919993   \n",
       "353     2.283096             1.0  2.799555              0.688189   \n",
       "354     7.896229             1.0  4.028388              0.102685   \n",
       "355     0.616272             1.0  1.235936              3.825898   \n",
       "\n",
       "     isi_violations_count  amplitude_cutoff  \n",
       "0                    1078           0.00309  \n",
       "1                     770            0.0067  \n",
       "2                      11          0.005223  \n",
       "3                     422          0.001179  \n",
       "4                      12          0.000694  \n",
       "..                    ...               ...  \n",
       "351                     9          0.001501  \n",
       "352                    73          0.000756  \n",
       "353                   158          0.000905  \n",
       "354                   282          0.083223  \n",
       "355                    64          0.032057  \n",
       "\n",
       "[356 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a113d-48de-4c2e-b2c6-7d0d43f5b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(amplitude_cutoff < 0.1) & (isi_violations_ratio < 1) & (presence_ratio > 0.9)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50c82f-6a55-486f-ba01-ce2be3081f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55ccd6-0014-400e-8d03-f4841f35bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c550b0b-d4e7-497e-8566-a24781dba18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmett\\anaconda3\\envs\\si_env\\Lib\\site-packages\\spikeinterface\\core\\job_tools.py:103: UserWarning: `n_jobs` is not set so parallel processing is disabled! To speed up computations, it is recommended to set n_jobs either globally (with the `spikeinterface.set_global_job_kwargs()` function) or locally (with the `n_jobs` argument). Use `spikeinterface.set_global_job_kwargs?` for more information about job_kwargs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f70ae0-3cdb-4249-9930-4b6e694d4c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1a832-b5f3-46f3-a5dc-9d623a240684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
